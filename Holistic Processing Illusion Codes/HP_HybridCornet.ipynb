{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Download CORnet-S model\n",
        "!pip uninstall -y cornet\n",
        "!pip install git+https://github.com/dicarlolab/CORnet\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1LLF52md3jvT",
        "outputId": "bf2a9c7c-351b-468a-970b-a75a9fd26ad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping cornet as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting git+https://github.com/dicarlolab/CORnet\n",
            "  Cloning https://github.com/dicarlolab/CORnet to /tmp/pip-req-build-jcv7b6y7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/dicarlolab/CORnet /tmp/pip-req-build-jcv7b6y7\n",
            "  Resolved https://github.com/dicarlolab/CORnet to commit d0cc17d4b34ad44dedb01683b70eafd15515adad\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from CORnet==0.1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from CORnet==0.1.0) (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from CORnet==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from CORnet==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from CORnet==0.1.0) (4.67.1)\n",
            "Collecting fire (from CORnet==0.1.0)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->CORnet==0.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->CORnet==0.1.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->CORnet==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->CORnet==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->CORnet==0.1.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=0.4.0->CORnet==0.1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=0.4.0->CORnet==0.1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=0.4.0->CORnet==0.1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=0.4.0->CORnet==0.1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=0.4.0->CORnet==0.1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=0.4.0->CORnet==0.1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=0.4.0->CORnet==0.1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=0.4.0->CORnet==0.1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=0.4.0->CORnet==0.1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->CORnet==0.1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->CORnet==0.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->CORnet==0.1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=0.4.0->CORnet==0.1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->CORnet==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->CORnet==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=0.4.0->CORnet==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->CORnet==0.1.0) (3.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->CORnet==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->CORnet==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->CORnet==0.1.0) (2025.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->CORnet==0.1.0) (11.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->CORnet==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=0.4.0->CORnet==0.1.0) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m127.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: CORnet, fire\n",
            "  Building wheel for CORnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for CORnet: filename=CORnet-0.1.0-py3-none-any.whl size=23226 sha256=f74cba224f305d9af2cc383a8fdfec1ec3f07f83d4f46aec04272a07269c2cbb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3h7fhsrh/wheels/3f/1b/1e/9ab1c622b7b6a87632001d7ac43f1957f53faa0a6b83f3e850\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=3ba61cc735fe851686dc46542350fccb8f764da9902f146a69009226f767f160\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built CORnet fire\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fire, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, CORnet\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed CORnet-0.1.0 fire-0.7.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a599d0e1d30e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from cornet.cornet_s import CORblock_S\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment\"\n",
        "DATA_ROOT = \"/content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /First Experiment/LFWCrop_dataset_pytorch\"\n",
        "PREVIOUS_MODELS_PATH = \"/content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Forth Experiment/models/pretrained/full_finetune\"\n",
        "\n",
        "MODEL_DIR = os.path.join(BASE_PATH, \"models\")\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"output\")\n",
        "\n",
        "def ensure_directories():\n",
        "    dirs = [\n",
        "        MODEL_DIR,\n",
        "        OUTPUT_DIR,\n",
        "        os.path.join(OUTPUT_DIR, \"training_curves\"),\n",
        "        os.path.join(OUTPUT_DIR, \"predictions\"),\n",
        "        os.path.join(OUTPUT_DIR, \"saliency\"),\n",
        "        os.path.join(OUTPUT_DIR, \"comparisons\"),\n",
        "        os.path.join(MODEL_DIR, \"hybrid\")\n",
        "    ]\n",
        "    for directory in dirs:\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "    print(\"所有必要的目录已创建\")\n",
        "\n",
        "ensure_directories()\n",
        "\n",
        "# Preopare to read the image pair\n",
        "def read_pairs(file_path, label):\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    return [(line.strip().split()[0], line.strip().split()[1], label) for line in lines]\n",
        "\n",
        "def load_all_pairs(list_dir):\n",
        "    all_pairs = []\n",
        "    for i in range(1, 11):\n",
        "        prefix = f\"{i:02d}\"\n",
        "        for split in [\"train\", \"test\"]:\n",
        "            same_file = os.path.join(list_dir, f\"{prefix}_{split}_same.txt\")\n",
        "            diff_file = os.path.join(list_dir, f\"{prefix}_{split}_diff.txt\")\n",
        "            all_pairs += read_pairs(same_file, 1)\n",
        "            all_pairs += read_pairs(diff_file, 0)\n",
        "    return all_pairs\n",
        "\n",
        "class FacePairsDataset(Dataset):\n",
        "    def __init__(self, pairs, image_dir, transform=None):\n",
        "        self.pairs = pairs\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform or transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name1, name2, label = self.pairs[idx]\n",
        "        name1 += \".ppm\"\n",
        "        name2 += \".ppm\"\n",
        "        img1 = Image.open(os.path.join(self.image_dir, name1)).convert(\"RGB\")\n",
        "        img2 = Image.open(os.path.join(self.image_dir, name2)).convert(\"RGB\")\n",
        "        return self.transform(img1), self.transform(img2), torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "def get_data_loaders():\n",
        "    face_dir = os.path.join(DATA_ROOT, \"faces\")\n",
        "    list_dir = os.path.join(DATA_ROOT, \"lists\")\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    pairs = load_all_pairs(list_dir)\n",
        "    split_idx = int(0.9 * len(pairs))\n",
        "    train_pairs = pairs[:split_idx]\n",
        "    val_pairs = pairs[split_idx:]\n",
        "\n",
        "    train_dataset = FacePairsDataset(train_pairs, face_dir, transform=transform)\n",
        "    val_dataset = FacePairsDataset(val_pairs, face_dir, transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=8, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader, train_dataset, val_dataset\n",
        "\n",
        "# Hybrid CORnet Model Design\n",
        "class HybridCORnetEmbedding(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super().__init__()\n",
        "        # Use Resnet18 as the backbone\n",
        "        self.resnet = models.resnet18(pretrained=pretrained)\n",
        "\n",
        "        # Use the 002 model (1 V1, 1 V2, 1 V4, 2 IT)\n",
        "        self.v2_time = 0\n",
        "        self.v4_time = 0\n",
        "        self.it_time = 2\n",
        "\n",
        "        # IT block\n",
        "        if self.it_time > 1:\n",
        "            self.IT_recurrent = CORblock_S(512, 512, times=self.it_time-1)\n",
        "\n",
        "        # HED structure (side conv)\n",
        "        self.side1 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=1),  # post V1 feature\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.side2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=1),  # post V2 feature\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.side3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=1),  # post V4 feature\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Feature Fusion\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1),  # 128x3 combined three features\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Attention Weights\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Conv2d(1024, 512, kernel_size=1),  # 512 backone + 512 fusion\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.Sigmoid()  # Generate weight attention between 0 - 1\n",
        "        )\n",
        "\n",
        "        # Pooling\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # V1: conv1 + bn1 + relu + maxpool\n",
        "        x = self.resnet.conv1(x)\n",
        "        x = self.resnet.bn1(x)\n",
        "        x = self.resnet.relu(x)\n",
        "        x1 = self.resnet.maxpool(x)\n",
        "\n",
        "        # V2: layer1\n",
        "        x2 = self.resnet.layer1(x1)\n",
        "\n",
        "        # V4: layer2\n",
        "        x3 = self.resnet.layer2(x2)\n",
        "\n",
        "        # IT: layer3 + layer4\n",
        "        x = self.resnet.layer3(x3)\n",
        "        x = self.resnet.layer4(x)\n",
        "        if self.it_time > 1:\n",
        "            x = self.IT_recurrent(x)\n",
        "\n",
        "        side1_feat = self.side1(x1)\n",
        "        side2_feat = self.side2(x2)\n",
        "        side3_feat = self.side3(x3)\n",
        "\n",
        "        side1_feat = F.adaptive_avg_pool2d(side1_feat, x.size()[2:])\n",
        "        side2_feat = F.adaptive_avg_pool2d(side2_feat, x.size()[2:])\n",
        "        side3_feat = F.adaptive_avg_pool2d(side3_feat, x.size()[2:])\n",
        "\n",
        "        fusion_feat = torch.cat([side1_feat, side2_feat, side3_feat], dim=1)\n",
        "        fusion_feat = self.fusion(fusion_feat)\n",
        "\n",
        "        combined = torch.cat([x, fusion_feat], dim=1)\n",
        "        attention_weights = self.attention(combined)\n",
        "\n",
        "        output = x * attention_weights + fusion_feat * (1 - attention_weights)\n",
        "\n",
        "        output = self.pool(output)\n",
        "        output = self.flatten(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Siamese\n",
        "class SiameseHybridCORnet(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super().__init__()\n",
        "        self.embedding_net = HybridCORnetEmbedding(pretrained=pretrained)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        f1 = self.embedding_net(x1)\n",
        "        f2 = self.embedding_net(x2)\n",
        "        return f1, f2\n",
        "\n",
        "class PretrainedCORnetEmbedding(nn.Module):\n",
        "    def __init__(self, times_dict, pretrained=True):\n",
        "        super().__init__()\n",
        "        self.resnet = models.resnet18(pretrained=pretrained)\n",
        "\n",
        "        def get_times(region): return times_dict.get(region, 2)\n",
        "        self.v2_time = get_times('V2')\n",
        "        self.v4_time = get_times('V4')\n",
        "        self.it_time = get_times('IT')\n",
        "\n",
        "        # V2: layer1输出 64\n",
        "        if self.v2_time > 1:\n",
        "            self.V2_recurrent = CORblock_S(64, 64, times=self.v2_time-1)\n",
        "\n",
        "        # V4: layer2 128\n",
        "        if self.v4_time > 1:\n",
        "            self.V4_recurrent = CORblock_S(128, 128, times=self.v4_time-1)\n",
        "\n",
        "        # IT: layer4 512\n",
        "        if self.it_time > 1:\n",
        "            self.IT_recurrent = CORblock_S(512, 512, times=self.it_time-1)\n",
        "\n",
        "        # Resnet Pooling\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # V1: conv1 + bn1 + relu + maxpool\n",
        "        x = self.resnet.conv1(x)\n",
        "        x = self.resnet.bn1(x)\n",
        "        x = self.resnet.relu(x)\n",
        "        x = self.resnet.maxpool(x)\n",
        "\n",
        "        # V2: layer1 (BasicBlock x2)\n",
        "        x = self.resnet.layer1(x)\n",
        "        if self.v2_time > 1:\n",
        "            x = self.V2_recurrent(x)\n",
        "\n",
        "        # V4: layer2 (BasicBlock x2)\n",
        "        x = self.resnet.layer2(x)\n",
        "        if self.v4_time > 1:\n",
        "            x = self.V4_recurrent(x)\n",
        "\n",
        "        # IT: layer3 (BasicBlock x2) + layer4 (BasicBlock x2)\n",
        "        x = self.resnet.layer3(x)\n",
        "        x = self.resnet.layer4(x)\n",
        "        if self.it_time > 1:\n",
        "            x = self.IT_recurrent(x)\n",
        "\n",
        "        x = self.pool(x)\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class SiamesePretrainedCORnet(nn.Module):\n",
        "    def __init__(self, times_dict, pretrained=True, freeze_backbone=False):\n",
        "        super().__init__()\n",
        "        self.embedding_net = PretrainedCORnetEmbedding(times_dict, pretrained=pretrained)\n",
        "\n",
        "        if freeze_backbone:\n",
        "            for param in self.embedding_net.resnet.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "            if hasattr(self.embedding_net, 'V2_recurrent'):\n",
        "                for param in self.embedding_net.V2_recurrent.parameters():\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            if hasattr(self.embedding_net, 'V4_recurrent'):\n",
        "                for param in self.embedding_net.V4_recurrent.parameters():\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            if hasattr(self.embedding_net, 'IT_recurrent'):\n",
        "                for param in self.embedding_net.IT_recurrent.parameters():\n",
        "                    param.requires_grad = True\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        f1 = self.embedding_net(x1)\n",
        "        f2 = self.embedding_net(x2)\n",
        "        return f1, f2\n",
        "\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "        loss = (label) * torch.pow(euclidean_distance, 2) + \\\n",
        "               (1 - label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
        "        return loss.mean()\n",
        "\n",
        "def compute_accuracy(out1, out2, labels, threshold=0.5):\n",
        "    distances = F.pairwise_distance(out1, out2)\n",
        "    preds = (distances < threshold).float()\n",
        "    correct = (preds == labels).float().sum()\n",
        "    accuracy = correct / labels.size(0)\n",
        "    return accuracy.item()\n",
        "\n",
        "def train_hybrid_model(num_epochs=10):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"使用设备: {device}\")\n",
        "\n",
        "    train_loader, val_loader, _, _ = get_data_loaders()\n",
        "\n",
        "    model = SiameseHybridCORnet(pretrained=True).to(device)\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"混合模型总参数数量: {total_params:,}\")\n",
        "    print(f\"可训练参数数量: {trainable_params:,}\")\n",
        "    print(f\"冻结参数比例: {100 * (total_params - trainable_params) / total_params:.2f}%\")\n",
        "\n",
        "    save_model_parameters_stats(model, \"hybrid\")\n",
        "\n",
        "    criterion = ContrastiveLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accuracies, val_accuracies = [], []\n",
        "\n",
        "    hybrid_model_dir = os.path.join(MODEL_DIR, \"hybrid\")\n",
        "    epoch_data_dir = os.path.join(hybrid_model_dir, \"epoch_data\")\n",
        "    os.makedirs(hybrid_model_dir, exist_ok=True)\n",
        "    os.makedirs(epoch_data_dir, exist_ok=True)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    best_epoch = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        for img1, img2, label in train_loader:\n",
        "            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                out1, out2 = model(img1, img2)\n",
        "                loss = criterion(out1, out2, label)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            acc = compute_accuracy(out1, out2, label)\n",
        "            running_loss += loss.item()\n",
        "            running_acc += acc\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = running_acc / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        with torch.no_grad():\n",
        "            for img1, img2, label in val_loader:\n",
        "                img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
        "\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    out1, out2 = model(img1, img2)\n",
        "                    loss = criterion(out1, out2, label)\n",
        "\n",
        "                acc = compute_accuracy(out1, out2, label)\n",
        "                running_loss += loss.item()\n",
        "                running_acc += acc\n",
        "\n",
        "        val_loss = running_loss / len(val_loader)\n",
        "        val_acc = running_acc / len(val_loader)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | 训练损失: {train_loss:.5f}, 训练准确率: {train_acc:.5f} | 验证损失: {val_loss:.5f}, 验证准确率: {val_acc:.5f}\")\n",
        "\n",
        "        epoch_results = {\n",
        "            'train_losses': train_losses,\n",
        "            'val_losses': val_losses,\n",
        "            'train_accs': train_accuracies,\n",
        "            'val_accs': val_accuracies,\n",
        "            'current_epoch': epoch + 1\n",
        "        }\n",
        "\n",
        "        with open(os.path.join(epoch_data_dir, f\"epoch_{epoch+1}_data.json\"), 'w') as f:\n",
        "            json.dump(epoch_results, f, indent=2)\n",
        "\n",
        "        if (epoch + 1) % 3 == 0 or epoch == num_epochs - 1 or val_acc > best_val_acc:\n",
        "            checkpoint = {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': train_loss,\n",
        "                'val_loss': val_loss,\n",
        "                'train_acc': train_acc,\n",
        "                'val_acc': val_acc\n",
        "            }\n",
        "\n",
        "            checkpoint_path = os.path.join(hybrid_model_dir, f\"checkpoint_epoch{epoch+1}.pt\")\n",
        "            torch.save(checkpoint, checkpoint_path)\n",
        "            print(f\"检查点已保存: {checkpoint_path}\")\n",
        "\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                best_epoch = epoch + 1\n",
        "                best_model_path = os.path.join(hybrid_model_dir, \"best_model.pt\")\n",
        "                torch.save(model.state_dict(), best_model_path)\n",
        "                print(f\"发现新的最佳模型 (验证准确率: {val_acc:.5f})，已保存到: {best_model_path}\")\n",
        "\n",
        "    plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies, \"hybrid\")\n",
        "\n",
        "    final_model_path = os.path.join(hybrid_model_dir, \"hybrid_model.pt\")\n",
        "    torch.save(model.state_dict(), final_model_path)\n",
        "    print(f\"最终模型已保存到: {final_model_path}\")\n",
        "\n",
        "    report = {\n",
        "        \"num_epochs\": num_epochs,\n",
        "        \"final_train_loss\": train_losses[-1],\n",
        "        \"final_val_loss\": val_losses[-1],\n",
        "        \"final_train_acc\": train_accuracies[-1],\n",
        "        \"final_val_acc\": val_accuracies[-1],\n",
        "        \"best_val_acc\": best_val_acc,\n",
        "        \"best_epoch\": best_epoch,\n",
        "        \"total_params\": total_params,\n",
        "        \"trainable_params\": trainable_params\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(hybrid_model_dir, \"training_report.json\"), 'w') as f:\n",
        "        json.dump(report, f, indent=2)\n",
        "\n",
        "    return model\n",
        "\n",
        "def save_model_parameters_stats(model, model_name=\"hybrid\"):\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    frozen_params = total_params - trainable_params\n",
        "\n",
        "    region_params = {}\n",
        "\n",
        "    if model_name == \"hybrid\":\n",
        "        resnet_params = sum(p.numel() for name, p in model.named_parameters()\n",
        "                         if 'embedding_net.resnet' in name and 'side' not in name\n",
        "                         and 'fusion' not in name and 'attention' not in name)\n",
        "        side_params = sum(p.numel() for name, p in model.named_parameters()\n",
        "                       if 'side' in name)\n",
        "        fusion_params = sum(p.numel() for name, p in model.named_parameters()\n",
        "                         if 'fusion' in name)\n",
        "        attention_params = sum(p.numel() for name, p in model.named_parameters()\n",
        "                           if 'attention' in name)\n",
        "        it_params = sum(p.numel() for name, p in model.named_parameters()\n",
        "                     if 'IT_recurrent' in name)\n",
        "\n",
        "        region_params = {\n",
        "            'ResNet骨干网络': resnet_params,\n",
        "            '侧边连接模块': side_params,\n",
        "            '特征融合模块': fusion_params,\n",
        "            '注意力机制': attention_params,\n",
        "            'IT递归层': it_params\n",
        "        }\n",
        "    else:\n",
        "        resnet_params = sum(p.numel() for name, p in model.named_parameters()\n",
        "                         if 'embedding_net.resnet' in name)\n",
        "        v2_params = sum(p.numel() for name, p in model.named_parameters()\n",
        "                     if 'V2_recurrent' in name)\n",
        "        v4_params = sum(p.numel() for name, p in model.named_parameters()\n",
        "                     if 'V4_recurrent' in name)\n",
        "        it_params = sum(p.numel() for name, p in model.named_parameters()\n",
        "                     if 'IT_recurrent' in name)\n",
        "\n",
        "        region_params = {\n",
        "            'ResNet骨干网络': resnet_params,\n",
        "            'V2递归层': v2_params,\n",
        "            'V4递归层': v4_params,\n",
        "            'IT递归层': it_params\n",
        "        }\n",
        "\n",
        "    stats_dir = os.path.join(MODEL_DIR, model_name)\n",
        "    os.makedirs(stats_dir, exist_ok=True)\n",
        "\n",
        "    stats = {\n",
        "        'model_name': model_name,\n",
        "        'total_params': total_params,\n",
        "        'trainable_params': trainable_params,\n",
        "        'frozen_params': frozen_params,\n",
        "        'frozen_ratio': frozen_params / total_params if total_params > 0 else 0,\n",
        "        'region_params': region_params\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(stats_dir, \"model_parameters_stats.json\"), 'w', encoding='utf-8') as f:\n",
        "        json.dump(stats, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    with open(os.path.join(stats_dir, \"model_parameters_stats.txt\"), 'w', encoding='utf-8') as f:\n",
        "        f.write(f\"# {model_name} 模型参数统计\\n\\n\")\n",
        "        f.write(f\"总参数数量: {total_params:,}\\n\")\n",
        "        f.write(f\"可训练参数数量: {trainable_params:,}\\n\")\n",
        "        f.write(f\"冻结参数数量: {frozen_params:,}\\n\")\n",
        "        f.write(f\"冻结参数比例: {100 * frozen_params / total_params:.2f}%\\n\\n\")\n",
        "\n",
        "        f.write(\"## 各区域参数分布\\n\\n\")\n",
        "        for region, count in region_params.items():\n",
        "            if count > 0:\n",
        "                f.write(f\"- {region}: {count:,} ({count/total_params*100:.2f}%)\\n\")\n",
        "\n",
        "    return stats\n",
        "\n",
        "def plot_training_curves(train_losses, val_losses, train_accs, val_accs, model_name=\"hybrid\"):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "    plt.plot(epochs, train_losses, 'b-', label='训练损失')\n",
        "    plt.plot(epochs, val_losses, 'r-', label='验证损失')\n",
        "    plt.title(f\"{model_name} 模型训练损失曲线\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"损失\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, [acc * 100 for acc in train_accs], 'b-', label='训练准确率')\n",
        "    plt.plot(epochs, [acc * 100 for acc in val_accs], 'r-', label='验证准确率')\n",
        "    plt.title(f\"{model_name} 模型训练准确率曲线\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"准确率 (%)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    curves_dir = os.path.join(OUTPUT_DIR, \"training_curves\")\n",
        "    os.makedirs(curves_dir, exist_ok=True)\n",
        "    save_path = os.path.join(curves_dir, f\"{model_name}_training_curves.png\")\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    print(f\"训练曲线已保存到: {save_path}\")\n",
        "    plt.close()\n",
        "\n",
        "def predict_models_comparison(hybrid_model_path):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    image_pairs = [\n",
        "        (\"/content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /First Experiment/Part_Whole_Illusion.jpg\",\n",
        "         \"/content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /First Experiment/Part_Whole_Illusion_n.jpg\",\n",
        "         \"Part_Whole_Illusion\"),\n",
        "\n",
        "        (\"/content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /First Experiment/Part_Whole_Illusion2.jpg\",\n",
        "         \"/content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /First Experiment/Part_Whole_Illusion_n2.jpg\",\n",
        "         \"Part_Whole_Illusion2\"),\n",
        "\n",
        "        (\"/content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /First Experiment/Margaret Thatcher_test2.jpg\",\n",
        "         \"/content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /First Experiment/Margaret Thatcher_test_n2.jpg\",\n",
        "         \"Margaret_Thatcher2\"),\n",
        "\n",
        "        (\"/content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /First Experiment/Margaret Thatcher_test.jpg\",\n",
        "         \"/content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /First Experiment/Margaret Thatcher_test_n.jpg\",\n",
        "         \"Margaret_Thatcher\")\n",
        "    ]\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Time Settings (Claim: This is different from the final number of blocks)\n",
        "    time_settings = {\n",
        "        \"0_0_1\": {\"V2\": 0, \"V4\": 0, \"IT\": 1},\n",
        "        \"0_0_2\": {\"V2\": 0, \"V4\": 0, \"IT\": 2},\n",
        "        \"0_0_4\": {\"V2\": 0, \"V4\": 0, \"IT\": 4},\n",
        "        \"0_2_1\": {\"V2\": 0, \"V4\": 2, \"IT\": 1},\n",
        "        \"0_2_2\": {\"V2\": 0, \"V4\": 2, \"IT\": 2},\n",
        "        \"0_2_4\": {\"V2\": 0, \"V4\": 2, \"IT\": 4},\n",
        "        \"2_4_1\": {\"V2\": 2, \"V4\": 4, \"IT\": 1},\n",
        "        \"2_4_2\": {\"V2\": 2, \"V4\": 4, \"IT\": 2},\n",
        "        \"2_4_4\": {\"V2\": 2, \"V4\": 4, \"IT\": 4},\n",
        "        \"5_10_5\": {\"V2\": 5, \"V4\": 10, \"IT\": 5}\n",
        "    }\n",
        "\n",
        "    early_models = [\"0_0_1\", \"0_0_2\", \"0_0_4\", \"0_2_1\", \"0_2_2\", \"0_2_4\"]\n",
        "\n",
        "    def sort_key(name):\n",
        "        return list(map(int, name.split(\"_\")))\n",
        "\n",
        "    hybrid_model = SiameseHybridCORnet(pretrained=False).to(device)\n",
        "    try:\n",
        "        hybrid_model.load_state_dict(torch.load(hybrid_model_path, map_location=device))\n",
        "        print(f\"加载混合模型成功: {hybrid_model_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"加载混合模型失败: {e}\")\n",
        "        return\n",
        "\n",
        "    pred_dir = os.path.join(OUTPUT_DIR, \"predictions\")\n",
        "    os.makedirs(pred_dir, exist_ok=True)\n",
        "\n",
        "    for img1_path, img2_path, name in image_pairs:\n",
        "        print(f\"\\n预测图片对: {name}\")\n",
        "\n",
        "        try:\n",
        "            img1 = transform(Image.open(img1_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
        "            img2 = transform(Image.open(img2_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
        "\n",
        "            results = {\n",
        "                'standard': {\"distances\": [], \"probs\": []},\n",
        "                'hybrid': {\"distances\": [], \"probs\": []}\n",
        "            }\n",
        "\n",
        "            hybrid_model.eval()\n",
        "            with torch.no_grad():\n",
        "                out1, out2 = hybrid_model(img1, img2)\n",
        "                dist = F.pairwise_distance(out1, out2).item()\n",
        "                prob = torch.sigmoid(torch.tensor(-10 * dist + 5)).item()\n",
        "\n",
        "            print(f\"混合模型 → 距离={dist:.4f}, 相同概率={prob:.4f}\")\n",
        "            results['hybrid']['distances'].append(dist)\n",
        "            results['hybrid']['probs'].append(prob)\n",
        "\n",
        "            sorted_keys = sorted(time_settings.keys(), key=sort_key)\n",
        "            for structure_name in sorted_keys:\n",
        "                times_dict = time_settings[structure_name]\n",
        "\n",
        "                model = SiamesePretrainedCORnet(times_dict, pretrained=False, freeze_backbone=False).to(device)\n",
        "\n",
        "                model_path = os.path.join(PREVIOUS_MODELS_PATH, f\"pretrained_model_T{structure_name}.pt\")\n",
        "\n",
        "                if os.path.exists(model_path):\n",
        "                    try:\n",
        "                        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "                    except Exception as e:\n",
        "                        print(f\"无法加载权重 {structure_name}: {e}\")\n",
        "                        continue\n",
        "                else:\n",
        "                    print(f\"未找到模型 {structure_name}, 跳过\")\n",
        "                    continue\n",
        "\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    out1, out2 = model(img1, img2)\n",
        "                    dist = F.pairwise_distance(out1, out2).item()\n",
        "                    prob = torch.sigmoid(torch.tensor(-10 * dist + 5)).item()\n",
        "\n",
        "                print(f\"{structure_name} → 距离={dist:.4f}, 相同概率={prob:.4f}\")\n",
        "                results['standard']['distances'].append(dist)\n",
        "                results['standard']['probs'].append(prob)\n",
        "\n",
        "            std_probs = results['standard']['probs']\n",
        "            overall_max_idx = np.argmax(std_probs)\n",
        "\n",
        "            early_indices = [i for i, key in enumerate(sorted_keys) if key in early_models]\n",
        "            early_max_idx = early_indices[np.argmax([std_probs[i] for i in early_indices])]\n",
        "\n",
        "            plt.figure(figsize=(16, 6))\n",
        "\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.plot(sorted_keys, std_probs*100, 'b-o', label=\"Standard Models\", linewidth=1.5, alpha=0.7)\n",
        "\n",
        "            if overall_max_idx == early_max_idx:\n",
        "                plt.plot(sorted_keys[early_max_idx], std_probs[early_max_idx], 'ro', markersize=8,\n",
        "                         label=f'Highest ({sorted_keys[early_max_idx]})', zorder=10)\n",
        "            else:\n",
        "                plt.plot(sorted_keys[overall_max_idx], std_probs[overall_max_idx], 'mo', markersize=8,\n",
        "                         label=f'Overall Highest ({sorted_keys[overall_max_idx]})', zorder=11)\n",
        "                plt.plot(sorted_keys[early_max_idx], std_probs[early_max_idx], 'ro', markersize=8,\n",
        "                         label=f'Early Models Highest ({sorted_keys[early_max_idx]})', zorder=10)\n",
        "\n",
        "            plt.axhline(y=results['hybrid']['probs'][0] * 100, color='g', linestyle='--',\n",
        "                       label=f'Hybrid Model ({results[\"hybrid\"][\"probs\"][0]*100:.1f}%)')\n",
        "\n",
        "            plt.title(f\"Model Comparison - {name}\")\n",
        "            plt.xlabel(\"Time Settings\")\n",
        "            plt.ylabel(\"Probability (%)\")\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            plt.legend()\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "\n",
        "            compare_models = ['0_0_2', '0_0_4', 'Hybrid']\n",
        "\n",
        "            idx_002 = sorted_keys.index('0_0_2')\n",
        "            idx_004 = sorted_keys.index('0_0_4')\n",
        "\n",
        "            compare_probs = [\n",
        "                std_probs[idx_002] * 100,\n",
        "                std_probs[idx_004] * 100,\n",
        "                results['hybrid']['probs'][0] * 100\n",
        "            ]\n",
        "\n",
        "            compare_distances = [\n",
        "                results['standard']['distances'][idx_002],\n",
        "                results['standard']['distances'][idx_004],\n",
        "                results['hybrid']['distances'][0]\n",
        "            ]\n",
        "\n",
        "            x = np.arange(len(compare_models))\n",
        "            width = 0.35\n",
        "\n",
        "            ax1 = plt.gca()\n",
        "            ax2 = ax1.twinx()\n",
        "\n",
        "            bars1 = ax1.bar(x - width/2, compare_distances, width, color='blue', alpha=0.7, label='Distance')\n",
        "            ax1.set_ylabel('Distance', color='blue')\n",
        "            ax1.tick_params(axis='y', labelcolor='blue')\n",
        "\n",
        "            bars2 = ax2.bar(x + width/2, compare_probs, width, color='orange', alpha=0.7, label='Probability')\n",
        "            ax2.set_ylabel('Probability (%)', color='orange')\n",
        "            ax2.tick_params(axis='y', labelcolor='orange')\n",
        "\n",
        "            for i, d in enumerate(compare_distances):\n",
        "                ax1.text(x[i] - width/2, d + 0.02, f\"{d:.4f}\", ha='center')\n",
        "\n",
        "            for i, p in enumerate(compare_probs):\n",
        "                ax2.text(x[i] + width/2, p + 1, f\"{p:.1f}%\", ha='center')\n",
        "\n",
        "            plt.title(f\"Detailed Comparison - {name}\")\n",
        "            plt.xticks(x, compare_models)\n",
        "            plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "            save_path = os.path.join(pred_dir, f\"{name}_models_comparison.png\")\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            print(f\"保存比较图 → {save_path}\")\n",
        "            plt.close()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"处理图片对 {name} 时出错: {e}\")\n",
        "\n",
        "def generate_hybrid_saliency_maps(dataset, hybrid_model_path, top_percent=0.1, intensity=0.9, num_images=10):\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    save_dir = os.path.join(OUTPUT_DIR, \"saliency/hybrid_model\")\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    hybrid_model = SiameseHybridCORnet(pretrained=False).to(device)\n",
        "    if os.path.exists(hybrid_model_path):\n",
        "        try:\n",
        "            hybrid_model.load_state_dict(torch.load(hybrid_model_path, map_location=device))\n",
        "            print(f\"加载混合模型成功: {hybrid_model_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"加载混合模型失败: {e}\")\n",
        "            print(\"使用初始化权重\")\n",
        "    else:\n",
        "        print(f\"未找到模型文件: {hybrid_model_path}\")\n",
        "        print(\"使用初始化权重\")\n",
        "\n",
        "    hybrid_model.eval()\n",
        "\n",
        "    for i in range(num_images):\n",
        "        img_tensor, _, _ = dataset[i]\n",
        "        img_tensor = img_tensor.unsqueeze(0).to(device).requires_grad_()\n",
        "\n",
        "        hybrid_model.zero_grad()\n",
        "        out1, _ = hybrid_model(img_tensor, img_tensor)\n",
        "        score = out1.norm()\n",
        "        score.backward()\n",
        "\n",
        "        saliency, _ = torch.max(img_tensor.grad.data.abs(), dim=1)\n",
        "        saliency = saliency[0].detach().cpu().numpy()\n",
        "\n",
        "        flat_saliency = saliency.flatten()\n",
        "        num_top_pixels = int(len(flat_saliency) * top_percent)\n",
        "        threshold = np.partition(flat_saliency, -num_top_pixels)[-num_top_pixels]\n",
        "\n",
        "        img_np = img_tensor[0].detach().cpu().permute(1, 2, 0).numpy()\n",
        "        img_np = np.clip(img_np, 0, 1)\n",
        "        saliency_norm = (saliency - saliency.min()) / (saliency.max() - saliency.min() + 1e-5)\n",
        "        alpha = saliency_norm * intensity\n",
        "\n",
        "        modified_img = img_np.copy()\n",
        "        modified_img[..., 0] += alpha * (1 - modified_img[..., 0])\n",
        "        modified_img[..., 1] *= (1 - alpha)\n",
        "        modified_img[..., 2] *= (1 - alpha)\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
        "        axes[0].imshow(img_np)\n",
        "        axes[0].set_title(f\"Original image (Hybrid)\")\n",
        "        axes[0].axis(\"off\")\n",
        "\n",
        "        axes[1].imshow(modified_img)\n",
        "        axes[1].set_title(f\"Saliency map (Hybrid)\")\n",
        "        axes[1].axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        save_path = os.path.join(save_dir, f\"saliency_{i}.png\")\n",
        "        plt.savefig(save_path)\n",
        "        print(f\"Saved saliency map Hybrid sample {i} → {save_path}\")\n",
        "        plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FRuuWQe8ZTO",
        "outputId": "f8121826-fbc6-4272-a73f-d60b68f2c220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "所有必要的目录已创建\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    try:\n",
        "        print(\"=\"*50)\n",
        "        print(\"开始执行混合HED-CORnet模型实验\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        start_time = datetime.now()\n",
        "        print(f\"实验开始时间: {start_time}\")\n",
        "\n",
        "        ensure_directories()\n",
        "\n",
        "        print(\"\\n[1/3] 开始训练混合模型...\")\n",
        "        try:\n",
        "            hybrid_model = train_hybrid_model(num_epochs=10)\n",
        "            print(\"模型训练完成!\")\n",
        "        except Exception as e:\n",
        "            print(f\"训练过程中发生错误: {e}\")\n",
        "            print(\"尝试继续执行后续步骤...\")\n",
        "\n",
        "        print(\"\\n[2/3] 准备模型评估...\")\n",
        "        hybrid_model_path = os.path.join(MODEL_DIR, \"hybrid\", \"hybrid_model.pt\")\n",
        "\n",
        "        if not os.path.exists(hybrid_model_path):\n",
        "            print(f\"警告: 未找到保存的模型 {hybrid_model_path}\")\n",
        "            best_model_path = os.path.join(MODEL_DIR, \"hybrid\", \"best_model.pt\")\n",
        "            if os.path.exists(best_model_path):\n",
        "                hybrid_model_path = best_model_path\n",
        "                print(f\"将使用最佳模型: {best_model_path}\")\n",
        "            else:\n",
        "                print(\"警告: 未找到最佳模型，模型比较和显著图生成可能失败\")\n",
        "\n",
        "        print(\"加载数据集...\")\n",
        "        train_loader, val_loader, train_dataset, val_dataset = get_data_loaders()\n",
        "        print(\"\\n[3/3] 生成模型比较结果和显著图...\")\n",
        "        try:\n",
        "            predict_models_comparison(hybrid_model_path)\n",
        "            print(\"模型预测比较完成\")\n",
        "        except Exception as e:\n",
        "            print(f\"模型比较过程中发生错误: {e}\")\n",
        "\n",
        "        try:\n",
        "            generate_hybrid_saliency_maps(\n",
        "                dataset=val_dataset,\n",
        "                hybrid_model_path=hybrid_model_path,\n",
        "                top_percent=0.1,\n",
        "                intensity=0.9,\n",
        "                num_images=10\n",
        "            )\n",
        "            print(\"显著图生成完成\")\n",
        "        except Exception as e:\n",
        "            print(f\"显著图生成过程中发生错误: {e}\")\n",
        "\n",
        "        end_time = datetime.now()\n",
        "        duration = end_time - start_time\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"实验结束时间: {end_time}\")\n",
        "        print(f\"总耗时: {duration}\")\n",
        "        print(\"混合HED-CORnet模型实验完成!\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        experiment_summary = {\n",
        "            \"experiment_name\": \"混合HED-CORnet模型实验\",\n",
        "            \"start_time\": str(start_time),\n",
        "            \"end_time\": str(end_time),\n",
        "            \"duration_seconds\": duration.total_seconds(),\n",
        "            \"status\": \"完成\"\n",
        "        }\n",
        "\n",
        "        with open(os.path.join(MODEL_DIR, \"experiment_summary.json\"), 'w', encoding='utf-8') as f:\n",
        "            json.dump(experiment_summary, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"实验过程中发生严重错误: {e}\")\n",
        "        print(\"实验未能完全完成\")\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zfpRTXeR8dXZ",
        "outputId": "5a70b0c4-ffcf-4ef5-c283-984eb5d5fc7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "开始执行混合HED-CORnet模型实验\n",
            "==================================================\n",
            "实验开始时间: 2025-05-05 13:49:49.163588\n",
            "所有必要的目录已创建\n",
            "\n",
            "[1/3] 开始训练混合模型...\n",
            "使用设备: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 178MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "混合模型总参数数量: 52,827,816\n",
            "可训练参数数量: 52,827,816\n",
            "冻结参数比例: 0.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-8db61b7d93bd>:347: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "<ipython-input-3-8db61b7d93bd>:371: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "<ipython-input-3-8db61b7d93bd>:395: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | 训练损失: 4.75998, 训练准确率: 0.50001 | 验证损失: 0.96634, 验证准确率: 0.50133\n",
            "检查点已保存: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/checkpoint_epoch1.pt\n",
            "发现新的最佳模型 (验证准确率: 0.50133)，已保存到: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/best_model.pt\n",
            "Epoch 2/10 | 训练损失: 0.58411, 训练准确率: 0.50002 | 验证损失: 0.35475, 验证准确率: 0.50150\n",
            "检查点已保存: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/checkpoint_epoch2.pt\n",
            "发现新的最佳模型 (验证准确率: 0.50150)，已保存到: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/best_model.pt\n",
            "Epoch 3/10 | 训练损失: 0.28340, 训练准确率: 0.50253 | 验证损失: 0.22561, 验证准确率: 0.51479\n",
            "检查点已保存: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/checkpoint_epoch3.pt\n",
            "发现新的最佳模型 (验证准确率: 0.51479)，已保存到: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/best_model.pt\n",
            "Epoch 4/10 | 训练损失: 0.20588, 训练准确率: 0.54778 | 验证损失: 0.17668, 验证准确率: 0.64312\n",
            "检查点已保存: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/checkpoint_epoch4.pt\n",
            "发现新的最佳模型 (验证准确率: 0.64312)，已保存到: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/best_model.pt\n",
            "Epoch 5/10 | 训练损失: 0.16693, 训练准确率: 0.69424 | 验证损失: 0.14169, 验证准确率: 0.84159\n",
            "检查点已保存: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/checkpoint_epoch5.pt\n",
            "发现新的最佳模型 (验证准确率: 0.84159)，已保存到: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/best_model.pt\n",
            "Epoch 6/10 | 训练损失: 0.13549, 训练准确率: 0.86277 | 验证损失: 0.11132, 验证准确率: 0.96077\n",
            "检查点已保存: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/checkpoint_epoch6.pt\n",
            "发现新的最佳模型 (验证准确率: 0.96077)，已保存到: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/best_model.pt\n",
            "Epoch 7/10 | 训练损失: 0.10739, 训练准确率: 0.96434 | 验证损失: 0.08417, 验证准确率: 0.99518\n",
            "检查点已保存: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/checkpoint_epoch7.pt\n",
            "发现新的最佳模型 (验证准确率: 0.99518)，已保存到: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/best_model.pt\n",
            "Epoch 8/10 | 训练损失: 0.08253, 训练准确率: 0.99452 | 验证损失: 0.06207, 验证准确率: 0.99934\n",
            "检查点已保存: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/checkpoint_epoch8.pt\n",
            "发现新的最佳模型 (验证准确率: 0.99934)，已保存到: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/best_model.pt\n",
            "Epoch 9/10 | 训练损失: 0.06333, 训练准确率: 0.99939 | 验证损失: 0.04593, 验证准确率: 0.99967\n",
            "检查点已保存: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/checkpoint_epoch9.pt\n",
            "发现新的最佳模型 (验证准确率: 0.99967)，已保存到: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/best_model.pt\n",
            "Epoch 10/10 | 训练损失: 0.04916, 训练准确率: 0.99998 | 验证损失: 0.03476, 验证准确率: 1.00000\n",
            "检查点已保存: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/checkpoint_epoch10.pt\n",
            "发现新的最佳模型 (验证准确率: 1.00000)，已保存到: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/best_model.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-8db61b7d93bd>:583: UserWarning: Glyph 25439 (\\N{CJK UNIFIED IDEOGRAPH-635F}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-3-8db61b7d93bd>:583: UserWarning: Glyph 22833 (\\N{CJK UNIFIED IDEOGRAPH-5931}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-3-8db61b7d93bd>:583: UserWarning: Glyph 27169 (\\N{CJK UNIFIED IDEOGRAPH-6A21}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-3-8db61b7d93bd>:583: UserWarning: Glyph 22411 (\\N{CJK UNIFIED IDEOGRAPH-578B}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-3-8db61b7d93bd>:583: UserWarning: Glyph 35757 (\\N{CJK UNIFIED IDEOGRAPH-8BAD}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-3-8db61b7d93bd>:583: UserWarning: Glyph 32451 (\\N{CJK UNIFIED IDEOGRAPH-7EC3}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-3-8db61b7d93bd>:583: UserWarning: Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-3-8db61b7d93bd>:583: UserWarning: Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-3-8db61b7d93bd>:583: UserWarning: Glyph 39564 (\\N{CJK UNIFIED IDEOGRAPH-9A8C}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-3-8db61b7d93bd>:583: UserWarning: Glyph 35777 (\\N{CJK UNIFIED IDEOGRAPH-8BC1}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-3-8db61b7d93bd>:583: UserWarning: Glyph 20934 (\\N{CJK UNIFIED IDEOGRAPH-51C6}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-3-8db61b7d93bd>:583: UserWarning: Glyph 30830 (\\N{CJK UNIFIED IDEOGRAPH-786E}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-3-8db61b7d93bd>:583: UserWarning: Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-3-8db61b7d93bd>:589: UserWarning: Glyph 25439 (\\N{CJK UNIFIED IDEOGRAPH-635F}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(save_path, dpi=300)\n",
            "<ipython-input-3-8db61b7d93bd>:589: UserWarning: Glyph 22833 (\\N{CJK UNIFIED IDEOGRAPH-5931}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(save_path, dpi=300)\n",
            "<ipython-input-3-8db61b7d93bd>:589: UserWarning: Glyph 27169 (\\N{CJK UNIFIED IDEOGRAPH-6A21}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(save_path, dpi=300)\n",
            "<ipython-input-3-8db61b7d93bd>:589: UserWarning: Glyph 22411 (\\N{CJK UNIFIED IDEOGRAPH-578B}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(save_path, dpi=300)\n",
            "<ipython-input-3-8db61b7d93bd>:589: UserWarning: Glyph 35757 (\\N{CJK UNIFIED IDEOGRAPH-8BAD}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(save_path, dpi=300)\n",
            "<ipython-input-3-8db61b7d93bd>:589: UserWarning: Glyph 32451 (\\N{CJK UNIFIED IDEOGRAPH-7EC3}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(save_path, dpi=300)\n",
            "<ipython-input-3-8db61b7d93bd>:589: UserWarning: Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(save_path, dpi=300)\n",
            "<ipython-input-3-8db61b7d93bd>:589: UserWarning: Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(save_path, dpi=300)\n",
            "<ipython-input-3-8db61b7d93bd>:589: UserWarning: Glyph 39564 (\\N{CJK UNIFIED IDEOGRAPH-9A8C}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(save_path, dpi=300)\n",
            "<ipython-input-3-8db61b7d93bd>:589: UserWarning: Glyph 35777 (\\N{CJK UNIFIED IDEOGRAPH-8BC1}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(save_path, dpi=300)\n",
            "<ipython-input-3-8db61b7d93bd>:589: UserWarning: Glyph 20934 (\\N{CJK UNIFIED IDEOGRAPH-51C6}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(save_path, dpi=300)\n",
            "<ipython-input-3-8db61b7d93bd>:589: UserWarning: Glyph 30830 (\\N{CJK UNIFIED IDEOGRAPH-786E}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(save_path, dpi=300)\n",
            "<ipython-input-3-8db61b7d93bd>:589: UserWarning: Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(save_path, dpi=300)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "训练曲线已保存到: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/output/training_curves/hybrid_training_curves.png\n",
            "最终模型已保存到: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/hybrid_model.pt\n",
            "模型训练完成!\n",
            "\n",
            "[2/3] 准备模型评估...\n",
            "加载数据集...\n",
            "\n",
            "[3/3] 生成模型比较结果和显著图...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "加载混合模型成功: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/hybrid_model.pt\n",
            "\n",
            "预测图片对: Part_Whole_Illusion\n",
            "混合模型 → 距离=0.3986, 相同概率=0.7339\n",
            "0_0_1 → 距离=0.2515, 相同概率=0.9231\n",
            "0_0_2 → 距离=0.1124, 相同概率=0.9797\n",
            "0_0_4 → 距离=0.1151, 相同概率=0.9791\n",
            "0_2_1 → 距离=0.6601, 相同概率=0.1679\n",
            "0_2_2 → 距离=0.2829, 相同概率=0.8976\n",
            "0_2_4 → 距离=0.2659, 相同概率=0.9122\n",
            "2_4_1 → 距离=0.4051, 相同概率=0.7209\n",
            "2_4_2 → 距离=0.2654, 相同概率=0.9126\n",
            "2_4_4 → 距离=0.0953, 相同概率=0.9828\n",
            "5_10_5 → 距离=1.0914, 相同概率=0.0027\n",
            "处理图片对 Part_Whole_Illusion 时出错: x and y must have same first dimension, but have shapes (10,) and (1000,)\n",
            "\n",
            "预测图片对: Part_Whole_Illusion2\n",
            "混合模型 → 距离=0.4814, 相同概率=0.5463\n",
            "0_0_1 → 距离=0.1783, 相同概率=0.9615\n",
            "0_0_2 → 距离=0.2910, 相同概率=0.8899\n",
            "0_0_4 → 距离=0.0817, 相同概率=0.9850\n",
            "0_2_1 → 距离=1.2157, 相同概率=0.0008\n",
            "0_2_2 → 距离=0.1957, 相同概率=0.9545\n",
            "0_2_4 → 距离=0.9770, 相同概率=0.0084\n",
            "2_4_1 → 距离=0.1874, 相同概率=0.9579\n",
            "2_4_2 → 距离=0.3251, 相同概率=0.8518\n",
            "2_4_4 → 距离=0.1161, 相同概率=0.9789\n",
            "5_10_5 → 距离=0.9755, 相同概率=0.0085\n",
            "处理图片对 Part_Whole_Illusion2 时出错: x and y must have same first dimension, but have shapes (10,) and (1000,)\n",
            "\n",
            "预测图片对: Margaret_Thatcher2\n",
            "混合模型 → 距离=0.5412, 相同概率=0.3985\n",
            "0_0_1 → 距离=0.7632, 相同概率=0.0671\n",
            "0_0_2 → 距离=0.5628, 相同概率=0.3480\n",
            "0_0_4 → 距离=0.4646, 相同概率=0.5876\n",
            "0_2_1 → 距离=0.4098, 相同概率=0.7113\n",
            "0_2_2 → 距离=0.6230, 相同概率=0.2262\n",
            "0_2_4 → 距离=0.7762, 相同概率=0.0594\n",
            "2_4_1 → 距离=1.2283, 相同概率=0.0007\n",
            "2_4_2 → 距离=0.2563, 相同概率=0.9196\n",
            "2_4_4 → 距离=0.0796, 相同概率=0.9853\n",
            "5_10_5 → 距离=0.5143, 相同概率=0.4644\n",
            "处理图片对 Margaret_Thatcher2 时出错: x and y must have same first dimension, but have shapes (10,) and (1000,)\n",
            "\n",
            "预测图片对: Margaret_Thatcher\n",
            "混合模型 → 距离=1.6921, 相同概率=0.0000\n",
            "0_0_1 → 距离=4.6548, 相同概率=0.0000\n",
            "0_0_2 → 距离=0.4496, 相同概率=0.6235\n",
            "0_0_4 → 距离=0.2657, 相同概率=0.9124\n",
            "0_2_1 → 距离=3.5273, 相同概率=0.0000\n",
            "0_2_2 → 距离=0.8007, 相同概率=0.0471\n",
            "0_2_4 → 距离=3.0234, 相同概率=0.0000\n",
            "2_4_1 → 距离=4.2534, 相同概率=0.0000\n",
            "2_4_2 → 距离=1.3774, 相同概率=0.0002\n",
            "2_4_4 → 距离=0.6813, 相同概率=0.1403\n",
            "5_10_5 → 距离=291.5353, 相同概率=0.0000\n",
            "处理图片对 Margaret_Thatcher 时出错: x and y must have same first dimension, but have shapes (10,) and (1000,)\n",
            "模型预测比较完成\n",
            "加载混合模型成功: /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/models/hybrid/hybrid_model.pt\n",
            "Saved saliency map Hybrid sample 0 → /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/output/saliency/hybrid_model/saliency_0.png\n",
            "Saved saliency map Hybrid sample 1 → /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/output/saliency/hybrid_model/saliency_1.png\n",
            "Saved saliency map Hybrid sample 2 → /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/output/saliency/hybrid_model/saliency_2.png\n",
            "Saved saliency map Hybrid sample 3 → /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/output/saliency/hybrid_model/saliency_3.png\n",
            "Saved saliency map Hybrid sample 4 → /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/output/saliency/hybrid_model/saliency_4.png\n",
            "Saved saliency map Hybrid sample 5 → /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/output/saliency/hybrid_model/saliency_5.png\n",
            "Saved saliency map Hybrid sample 6 → /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/output/saliency/hybrid_model/saliency_6.png\n",
            "Saved saliency map Hybrid sample 7 → /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/output/saliency/hybrid_model/saliency_7.png\n",
            "Saved saliency map Hybrid sample 8 → /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/output/saliency/hybrid_model/saliency_8.png\n",
            "Saved saliency map Hybrid sample 9 → /content/drive/MyDrive/Colab Notebooks/NE240/Holistic Processing /Fifth Experiment/output/saliency/hybrid_model/saliency_9.png\n",
            "显著图生成完成\n",
            "\n",
            "==================================================\n",
            "实验结束时间: 2025-05-05 14:32:56.333448\n",
            "总耗时: 0:43:07.169860\n",
            "混合HED-CORnet模型实验完成!\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# shutil.rmtree('/content/drive/MyDrive/NE240/Holistic Processing /Fifth Experiment')"
      ],
      "metadata": {
        "id": "XxTm0dexDEzV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}